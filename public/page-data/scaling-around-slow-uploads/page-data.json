{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/\\scaling-around-slow-uploads","result":{"data":{"brainNote":{"slug":"scaling-around-slow-uploads","title":"scaling-around-slow-uploads","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Upload bandwidth is limited\"), mdx(\"p\", null, \"For regularly scheduled \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"%5Cdata-synchronization\"\n  }), \"Data Synchronization\"), \" with the cloud, the big struggle is our upload speed. I can download up to 330 Mbps with my connection, but my uploads are limited to only 30 Mbps. This was crushing my hopes as I did the initial upload of the backup data, as I was averaging about 1.5 hours per 10 GB chunk at best, or something like 6.5 GB/hr (roughly 2 MB/s). That's a little dissapointing given that I should be able to max out the pipe at roughly 3 MB/s, or about 50% better speed than I was getting. I \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"think\"), \" that the issue was that I wasn't hitting the pipe very hard, just uploading one file at a time sequentially. I think, if I spread these uploads out over multiple threads or processes, I'll get better throughput. The big question is, of course, what's the best way in which to do so? Python makes this less than easy or enjoyable natively. Should I turn to C# and service fabric? Do those even work on linux? I know C#/.NET 5 does, but what about service fabric? If they work on linux, do they work on ARM/the Pi? I doubt it, but worth looking into. What are the alternatives? \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[{"title":"the-homebackup-project","slug":"the-homebackup-project","childMdx":{"excerpt":"Backing Up Critical Data This is an offshoot of my  The Personal DataVault  project, really a first 'research-ish' step along the way to…"}}],"outboundReferenceNotes":[{"title":"data-synchronization","slug":"data-synchronization","childMdx":{"excerpt":"Synchronizing Disparate Data Sources This is something that OneDrive, Google Drive, Dropbox, and many others are quite good at. Effectively…"}}]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"scaling-around-slow-uploads"}},"staticQueryHashes":[]}