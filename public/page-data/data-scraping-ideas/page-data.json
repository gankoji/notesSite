{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/\\data-scraping-ideas","result":{"data":{"brainNote":{"slug":"data-scraping-ideas","title":"data-scraping-ideas","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Discovering Data\"), mdx(\"p\", null, \"Had some thoughts today as I was mulling over my little 'walk the tree' project from TrashNukem this week. It occurred to me that what I was doing by walking a directory tree recursively, was actually super applicable to this project as well. If I recurse through directories, processing every single file in parallel, that processing can be whatever I want it to be. \"), mdx(\"p\", null, \"In this case, I want it to be a few things. I want it to be hashing the file contents and metadata, and adding that hash to a 'found' set, for deduplication. I want it to be adding the file metadata to some other data store type, where I can also look for duplicate file names or other fields, and ask the user to intelligently identify if those duplicate metadata lists are real dupes or not. Finally, I can probably use this per file processing to ingest the data into some sort of datastore that allows for easier discoverability, like tagging, linking, searching through metadata, and other forms of association. Questions abound as to what type of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"%5Cdatabase\"\n  }), \"Database\"), \" or store to use, what types of \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"%5Cdata-structures\"\n  }), \"Data Structures\"), \" are appropriate for each of these bits, but that's all to be sorted out once I get started on implementation. Just thought it would be cool to get this all out of my head and down into text. \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[],"outboundReferenceNotes":[{"title":"database","slug":"database","childMdx":{"excerpt":""}},{"title":"data-structures","slug":"data-structures","childMdx":{"excerpt":"Project - Data Structures GreedSort Other Data Structures B-Trees \n 20200620175608-b_trees \n 20200620210305-heaps_data_structure \n LRU cacheâ€¦"}}]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"data-scraping-ideas"}},"staticQueryHashes":[]}