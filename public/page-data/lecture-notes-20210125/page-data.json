{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/\\lecture-notes-20210125","result":{"data":{"brainNote":{"slug":"lecture-notes-20210125","title":"lecture-notes-20210125","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"lecture-notes-20210125\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Constrained Optimization\"), mdx(\"p\", null, \"Covering the general form of optimization problems with constraints, and on to Lagrangians. Somehow, we'll look to incorporate the idea of duality with Lagrangians, hopefully today (since that's on the homework!). \"), mdx(\"p\", null, \"We have a short discussion on optimization problems in general, how they are hard, and there are no good known algorithms for solving them in the general (fully nonlinear) case which aren't effectively 'brute force', i.e. searching the entire feasible set. \"), mdx(\"h2\", null, \"An algorithmic idea\"), mdx(\"p\", null, \"One thing that I just thought up with respect to searching the entire feasible set, applies mainly to 'smooth' problems, is a variation on successive refinement over a grid. The issue with a grid search is that you run the risk of 'missing' a narrow well/peak when your grid is too coarse. One way to look for those is to shift the original grid (while it's still relatively small), any number of times, in small amounts along the search directions. Then, we calculate the objective value over the grid again, and look at how much this new grid of obj vals has changed from the previous. After we do this enough to get enough information regarding local smoothness, we can proceed with bounding and refinement, this time with higher confidence that we've not missed any areas of interest. \"), mdx(\"p\", null, \"This approach doesn't completely remove the risk, but it does mitigate it somewhat. \"), mdx(\"h2\", null, \"Lagrangian\"), mdx(\"p\", null, \"The lagrangian is simply a function:\"), mdx(\"p\", null, \"$L(x, \\\\lambda, \\\\mu) = f_0(x) + \\\\sum_i\\\\lambda_i f_i(x) + \\\\sum_j \\\\mu_j h_j(x)$\"), mdx(\"p\", null, \"$\\\\lambda, \\\\mu$ are the dual variables, and $(\\\\lambda, \\\\mu)$ is dual feasible if $\\\\lambda \\\\geq 0$. \"), mdx(\"p\", null, \"This is easy enough to bound: for any primal feasible point and for any dual feasible variables, we have that $L(x, \\\\lambda, \\\\mu) \\\\leq f\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"0(x)$. Note this is a pointwise inequality. To get a bound over the whole set of feasible $x$, we define a new function: $$g(\\\\lambda, \\\\mu) = inf\"), \"{x\\\\in D} L(x, \\\\lambda, \\\\mu)$$ \"), mdx(\"p\", null, \"This doesn't seem particularly useful, since it trades one minimization problem for infinitely many, one of which (when $\\\\lambda, \\\\mu$ are zero) is the original problem. One interesting fact though: $g$ is the pointwise infimum of a set of affine functions, and thus $g$ is always concave. \"), mdx(\"h2\", null, \"Weak Duality\"), mdx(\"p\", null, \"We know that \"), mdx(\"p\", null, \"$$p^\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \" = inf_{x\\\\in D} f_0(x)$$\\n$$d^\"), \" = sup_{\\\\lambda \\\\geq 0} g(\\\\lambda, \\\\mu)$$\"), mdx(\"p\", null, \"This $d^\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"$ can be computed numerically. We also have the $p^\"), \" \\\\geq d^\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"$, with equality only at the solution point $x^\"), \"$, and the solution point for the dual method $\\\\lambda^\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \", \\\\mu^\"), \"$. We call $p^\", mdx(\"em\", {\n    parentName: \"p\"\n  }, \" - d^\"), \"$ the \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"duality gap\")), \". \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[],"outboundReferenceNotes":[]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"lecture-notes-20210125"}},"staticQueryHashes":[]}