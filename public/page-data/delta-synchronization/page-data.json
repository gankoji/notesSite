{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/\\delta-synchronization","result":{"data":{"brainNote":{"slug":"delta-synchronization","title":"delta-synchronization","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"Storing Sync Results\"), mdx(\"p\", null, \"Do I really need (or even want!?) to use a database or other persistent store to do all of this processing, or do I just want to do it on the fly? Rsync does it on the fly, calculating the deltas at every invocation. \"), mdx(\"p\", null, \"For local and local-network destinations, I suppose the round trip latency is small enough that it doesn't really factor into the overall speed of this, and the major bottleneck is the performance of the storage medium from which we're reading the data to calculate the deltas. Thus, it's performance only tends to get noticeably bad once the data size gets really large (or the number of files grows very large). \"), mdx(\"p\", null, \"However, in the case of a cloud sync app, this bottleneck is very likely to get dwarfed by the round trip latency through the network. So, what are the options here? And what is a reasonable plan of attack, given how efficient and effective I am with Clojure currently? (That's to say: not really at all!). \"), mdx(\"h2\", null, \"Alternatives to Re-calc\"), mdx(\"p\", null, \"If we don't want to recalculate the delta sync at every sync time, we have to store the results somewhere, and recall them for future use. Given that the service could be shut down and restarted (or hang, etc) in between sync period endpoints, that means we're going to have to persist this data somewhere that's not main memory.  There are a plethora of options for doing so:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"File based persistence (text or binary)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Relational database persistence\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Document DBs\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Graph DBs, other 'exotic' or niche types. \")), mdx(\"p\", null, \"Modern RDBMS' are quite popular for distributed access to a centralized datastore, and have tons of infrastructure built around them for enabling that on a pretty big scale. All of the big cloud providers have at least some sort of RDBMS (usually some variant of SQL) that they provide on demand, and of course do their best to lock you into. Most of them have some sort of NoSQL DBMS as well, and if you can't get that product directly as a service, there's likely to be a VM image/template that someone has created and released that let's you get it set up quickly, albeit slightly less quickly than the resource provider versions. \"), mdx(\"h2\", null, \"SQL vs DocumentDB?\"), mdx(\"p\", null, \"One thing I'm not super clear on here is whether there's a real performance difference between SQL DBs and DocumentDBs like Mongo for this use case. I know the real driver in moving to something like Mongo is really about schema flexibility (rather, schema-less-ness), which may or may not apply here, since this isn't a terribly complicated usage of persistence. \"), mdx(\"h1\", null, \"The Use Case?\"), mdx(\"p\", null, \"How exactly do I plan to use this stuff anyway? The stated goal is \\\"don't recalculate the delta at every synchronization interval.\\\" How would a SQL/NoSQL/File persistence scheme achieve that, anyway? To answer that, we really need to answer how we calculate the delta in the first place. \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"%5Crsyncs-delta-calculation\"\n  }), \"Rsync's Delta Calculation\"), \" can serve as a good starting point here. \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[{"title":"making-architectural-decisions","slug":"making-architectural-decisions","childMdx":{"excerpt":"The HomeBackup Project Next, the architecture plan: Think through  Clojure Deployment . Figure out a convenient way to get this code up and…"}}],"outboundReferenceNotes":[{"title":"rsyncs-delta-calculation","slug":"rsyncs-delta-calculation","childMdx":{"excerpt":"Old Faithful Rsync is a really sick little tool. It effectively synchronizes file trees between disparate locations, and does so in a very…"}}]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"delta-synchronization"}},"staticQueryHashes":[]}