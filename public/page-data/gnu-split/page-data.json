{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/\\gnu-split","result":{"data":{"brainNote":{"slug":"gnu-split","title":"gnu-split","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"gnu-split\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h1\", null, \"GNU Split\"), mdx(\"p\", null, \"Is super effective! It does exactly what you'd expect it to, given the name: splits up an input file into chunks, according to the size parameter you give it in the call. I used it the other day to take a 471GB gzipped tarball and split it into 10GB chunks for uploading to my blob storage account in Azure. The command looked something like this: \"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"split -b 10G backup20201210.tar.gz backup20201210.tar.gz.part\\n\")), mdx(\"p\", null, \"The last part of the command is the 'prefix' for the name of the split files. I ended up with a bunch of files named 'backup20201210.tar.gz.partaa' going through the alphabet. \"), mdx(\"h2\", null, \"Putting them back together again, though?\"), mdx(\"p\", null, \"Is actually super simple, and only requires use of the infamous \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cat\"), \" program. One way is to simply rely on shell expansion:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"cat backup20201210.tar.gz.part* > backup20201210.tar.gz\\n\")), mdx(\"p\", null, \"However, shell expansion order depends upon the locale of the local system. To prevent out of order errors, we need to be a little more careful. One suggestion is to type out the wildcard input, hit escape, and then tab, which should cause the expansion to happen before the command is run. This gives the operator an opportunity to correct the order. A better solution might involve pulling the part file names into a list in a bash script, alphabetizing by the suffix, and then looping over that list with calls to cat with an append operator. \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[{"title":"cloud-backup","slug":"cloud-backup","childMdx":{"excerpt":"Keeping Offsite Backups Moving data to the cloud  is an atrocious experience, mostly because of the fact that American ISPs are the worst inâ€¦"}}],"outboundReferenceNotes":[]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"gnu-split"}},"staticQueryHashes":[]}