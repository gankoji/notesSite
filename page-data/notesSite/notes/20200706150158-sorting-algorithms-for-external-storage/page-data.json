{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/notesSite/notes/20200706150158-sorting-algorithms-for-external-storage","result":{"data":{"brainNote":{"slug":"20200706150158-sorting-algorithms-for-external-storage","title":"20200706150158-sorting-algorithms-for-external-storage","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"20200706150158-sorting-algorithms-for-external-storage\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"So here's where I start ideating for the sort program. When it comes to sorting datasets that can fit in memory, there are well known approaches: Python's Timsort is widely recognized as one of the best, and it's basically a well tuned quicksort with good heuristics. There's bubblesort and mergesort, as well as heap and tree sort as well. I think, though, when it comes to datasets that can't fit in main memory, the options become significantly more limited. Knuth's book details how to do this with merge sort, so that's probably the canonical way to go. I think that getting a \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"correct\"), \" external sort up and running on a pi would be a short, weekend ish project. But getting an external sort that fully saturates IO buses \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"and\"), \" CPU cores for maximum performance is going to be a real trick.\"), mdx(\"p\", null, \"One idea I had today was that I could do the sort using a B-tree with a high branching factor (somewhere in the 200-300 range, for optimal height), and then just read the tree out in order to the sort file. Might not be the best performing option, but B-trees \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"are\"), \" a high performance option when considering datasets that can't fit in main memory. It's worth a look. Might take some tweaking to get pages from disk prefetched and such.\"), mdx(\"p\", null, \"So fun fact, a B-tree with 10\", mdx(\"sup\", null, \"12\"), \" records (for 100 byte records, this would be the 100 TB sort category) would have a maximum height of 5. That's it! That height goes down to 4 for the 10\", mdx(\"sup\", null, \"10\"), \" records categories (e.g. JouleSort, since that's the only remaining category in JouleSort). That means that our insertions are going to be fast as hell, since we have to make a maximum of 800 or 1000 comparisons for each element. That's not great, actually, now that I do the math, since most sorting routines take nlogn comparisons to achieve. We'll need to do something more efficient than just iterating through the pages/nodes in the tree when we insert. Probably a binary search on each node, that cuts the comparisons down pretty significantly. Gotta look through Knuth's implementation and notes again to get that down.\"), mdx(\"p\", null, \"This note is getting long, continuing in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"20200706152534-sorting_algorithms_part_2\"\n  }), \"Sorting Algorithms part 2\"), \".\"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[],"outboundReferenceNotes":[]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"20200706150158-sorting-algorithms-for-external-storage"}},"staticQueryHashes":[]}