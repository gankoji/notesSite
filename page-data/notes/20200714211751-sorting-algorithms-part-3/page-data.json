{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/notes/20200714211751-sorting-algorithms-part-3","result":{"data":{"brainNote":{"slug":"20200714211751-sorting-algorithms-part-3","title":"20200714211751-sorting-algorithms-part-3","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"20200714211751-sorting-algorithms-part-3\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"I was fortunate enough over the last week to stumble across an excellent text by Jeffrey Vitter called \\\"Algorithms and Data Structures for External Memory\\\", that just so happens to go over the optimal known methods for handling this \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"exact\"), \" problem that I've been mulling over, among others. The book is actually packed full of useful conceptual information. It goes over the very useful (and fairly accurate) Parallel Disk Model, and presents the key algorithmic concepts behind the optimal methods for sorting, searching, FFT, permutations, matrix computations, and a whole host of other crucial pieces of computing. This is actually really awesome, given that most of the current body of knowledge in this area absolutely shits the bed as soon as the working set becomes too massive to fit in main memory.\"), mdx(\"p\", null, \"Aaaaanyway, turns out that my half-baked idea for creating a B-Tree and then traversing it in order wasn't a very good one. The best known algorithms for optimal external memory sorting are variants of Distribution and Merge sorts. Random Cycling Merge sort is one of the variants that they propound as actually getting close (in terms of 'small constant factors away') to the optimal bound in IOs needed, as well as in keeping all disks in use at or close to full throughput utilization for the duration of the sort. The best part about Vitter's book is the 300 ish references he includes all throughout the text. He doesn't provide any concrete implementations or even pseudocode for the algorithmic concepts he describes, but the references do. This gives the text a very Knuth-like thoroughness, but lets the reader separate the various pieces of the learning into larger chunks, which I like a bit better. Of course, Knuth as a reference is irreplacable, but not so much as a learning text.\"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[],"outboundReferenceNotes":[]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"20200714211751-sorting-algorithms-part-3"}},"staticQueryHashes":[]}