{"componentChunkName":"component---node-modules-gatsby-theme-andy-src-templates-note-js","path":"/notes/looking-into-java-based-technologies","result":{"data":{"brainNote":{"slug":"looking-into-java-based-technologies","title":"looking-into-java-based-technologies","childMdx":{"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", null, \"A Ton of Java GPGPU Resources\"), mdx(\"p\", null, \"This morning (20201019), I shifted my focus from GPU centric technologies like CUDA/OpenCL and the others mentioned in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"/notes/current-state-of-the-art\"\n  }), \"Current state of the art\"), \", and more towards the JVM. Turns out that there have already been quite a few attempts at enabling GPGPU from within the java language, in much the same way as Altimesh and others did with C++ and C#: code decoration. \"), mdx(\"h3\", null, \"Compiler Add-ons/Code Generators\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://aparapi.github.io/\"\n  }), \"Aparapi\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/millecker/rootbeer1\"\n  }), \"Rootbeer\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://code.google.com/archive/p/java-gpu/\"\n  }), \"Java-GPU\"), \", and a few others are all extensions to the standard Java compiler, which allow for code generation to an OpenCL target via code decoration. \"), mdx(\"h3\", null, \"Binding Libraries\"), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://jocl.org\"\n  }), \"JOCL\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://jcuda.org\"\n  }), \"JCUDA\"), \", and a few others. These are basically Java libraries which effectively allow you to incorporate complete CUDA/OpenCL programs into your Java code. Not at all useful in the context of 'pushing GPGPU one level up the chain,' but could be useful as targets?\"), mdx(\"h3\", null, \"TornadoVM and GraalVM\"), mdx(\"p\", null, \"First, \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/beehive-lab/TornadoVM\"\n  }), \"TornadoVM\"), \". Tornado is actually a plugin to OpenJDK and GraalVM that 'allows programmers to automatically run Java programs on heterogeneous hardware.' It's pretty handy, as there's very little to add to code that already works for CPUs only in order to get them to run on the GPU. Really, though, this falls under 'code generators.'\"), mdx(\"p\", null, \"Next, \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.graalvm.org/docs/introduction/\"\n  }), \"GraalVM\"), \". GraalVM is a platform like the JVM, and it supports interpreters and such written in Java. I don't see anything about it specifically related to heterogeneous computing, but it is marketed as a 'high-performance' alternative to the JVM. \"));\n}\n;\nMDXContent.isMDXComponent = true;"},"inboundReferenceNotes":[{"title":"gpgpu-productivity","slug":"gpgpu-productivity","childMdx":{"excerpt":"Improving GPGPU This project is aimed at finding out about the latest and greatest in GPGPU technology, looking for tools, platforms, and…"}}],"outboundReferenceNotes":[{"title":"current-state-of-the-art","slug":"current-state-of-the-art","childMdx":{"excerpt":"GPGPU Tools on the Market OpenACC OpenACC  is a mature set of extensions to native C compilers that allow the programmer to decorate…"}}]},"site":{"siteMetadata":{"title":"Jake's Notes"}}},"pageContext":{"slug":"looking-into-java-based-technologies"}},"staticQueryHashes":[]}